{"type": "refactor_task", "created_by": "dan.amarilho", "created_at": "2025-06-04T00:00:00Z", "status": "pending", "id": "task_llm_fallback_local", "title": "Adicionar fallback local ao llm_proxy_hard.py", "description": "Implementar mecanismo para usar WASM local (mistral.wasm) antes de chamar LLM remoto. Incluir cache sem\u00e2ntico por hash de prompt."}
{"type": "refactor_task", "created_by": "dan.amarilho", "created_at": "2025-06-04T00:00:00Z", "status": "pending", "id": "task_llm_timeout_retry", "title": "Configurar timeout e retry no llm_proxy_hard.py", "description": "Adicionar `timeout`, `retry` e tratamento de exce\u00e7\u00f5es no proxy LLM. Garantir logs claros em stderr e resposta padronizada em JSON."}
